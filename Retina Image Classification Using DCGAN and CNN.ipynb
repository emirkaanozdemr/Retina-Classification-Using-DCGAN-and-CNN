{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retina Image Classification Using DCGAN and CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data:image/jpeg;base64,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\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Introduction: Retina Image Classification Using DCGAN and CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 17px\">In this project, we aim to develop a robust system for classifying real and synthetic retina images using advanced machine learning techniques. The primary objective is to generate synthetic retina images from a single eye photo using Deep Convolutional Generative Adversarial Networks (DCGAN) and then classify these images using a Convolutional Neural Network (CNN).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**1. Image Extraction**: We start by capturing a single eye photo from a person's face. Using computer vision techniques, we extract the retina region from the eye photo. This step is crucial for creating a dataset that closely resembles real retinal images.\n",
    "\n",
    "**2. Data Collection**: We compile a dataset of 1000 real retina images. These images serve as the ground truth for our project and will be used to train our models.\n",
    "\n",
    "**3. Synthetic Image Generation**: Leveraging the power of DCGAN, we generate 1000 synthetic retina images. DCGAN consists of two main components: a generator that creates new images and a discriminator that tries to distinguish between real and fake images. Through iterative training, the generator improves its ability to produce realistic retina images.\n",
    "\n",
    "**4. Data Labeling**: The real retina images are labeled as '1', while the synthetic images are labeled as '0'. This labeled dataset is essential for training our classification model.\n",
    "\n",
    "**5. Model Training**: We build and train a CNN model using the labeled dataset. The CNN will learn to differentiate between real and synthetic retina images based on the features it extracts during training.\n",
    "\n",
    "**6. Evaluation and Optimization**: We evaluate the performance of our CNN model on a validation set. To enhance the accuracy of our model, we perform hyperparameter tuning and other optimization techniques.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Significance of the Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 17px\">The ability to accurately classify real and synthetic retina images has significant implications in various fields, including medical diagnostics and security. By improving the accuracy of such classifications, we can enhance the reliability of automated systems that rely on retinal imaging.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T10:27:52.537639Z",
     "iopub.status.busy": "2024-07-06T10:27:52.537065Z",
     "iopub.status.idle": "2024-07-06T10:27:54.067944Z",
     "shell.execute_reply": "2024-07-06T10:27:54.066633Z",
     "shell.execute_reply.started": "2024-07-06T10:27:52.537598Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "ouput_dir = \"/kaggle/working/retina_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "data = []\n",
    "\n",
    "image_path = \"/kaggle/input/retina/Fotograf - 6.07.2024 11.09.jpg\" \n",
    "frame = cv2.imread(image_path)\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "count = 0\n",
    "for (x, y, w, h) in faces:\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = frame[y:y+h, x:x+w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "\n",
    "    if len(eyes) < 2:\n",
    "        continue\n",
    "\n",
    "    eye_regions = []\n",
    "    for (ex, ey, ew, eh) in eyes:\n",
    "        eye_regions.append((ex, ey, ew, eh))\n",
    "    \n",
    "    for i in range(1000):\n",
    "        if count >= 1000:\n",
    "            break\n",
    "       \n",
    "        (ex, ey, ew, eh) = random.choice(eye_regions)\n",
    "        \n",
    "        \n",
    "        dx = random.randint(-10, 10)\n",
    "        dy = random.randint(-10, 10)\n",
    "        scale = random.uniform(0.8, 1.2)\n",
    "\n",
    "        cx, cy, cew, ceh = int(ex + dx), int(ey + dy), int(ew * scale), int(eh * scale)\n",
    "        cx = max(0, min(cx, roi_color.shape[1] - cew))\n",
    "        cy = max(0, min(cy, roi_color.shape[0] - ceh))\n",
    "\n",
    "         \n",
    "        retina = roi_color[cy:cy+ceh, cx:cx+cew]\n",
    "        \n",
    "        \n",
    "        retina_path = os.path.join(output_dir, f\"retina_{count}.png\")\n",
    "        cv2.imwrite(retina_path, retina)\n",
    "        data.append({\"image_id\": count, \"image_path\": retina_path})\n",
    "        count += 1\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"/kaggle/working/retina_images.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code processes an input image by first detecting faces and eyes using OpenCV's Haar Cascade classifiers. It then extracts eye regions from detected faces, applies random shifts and scaling to augment the data, and generates 1000 variations of these retina images. Each generated retina image is saved in a specified output directory, and metadata about the images, including their IDs and paths, is stored in a list. Finally, the metadata is saved as a CSV file, providing a comprehensive dataset of retina images for further analysis or machine learning purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T10:27:54.070837Z",
     "iopub.status.busy": "2024-07-06T10:27:54.070377Z",
     "iopub.status.idle": "2024-07-06T10:27:54.089678Z",
     "shell.execute_reply": "2024-07-06T10:27:54.088510Z",
     "shell.execute_reply.started": "2024-07-06T10:27:54.070794Z"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/kaggle/working/retina_images.csv\")\n",
    "df\n",
    "#Reading the paths of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T10:27:54.091834Z",
     "iopub.status.busy": "2024-07-06T10:27:54.091373Z",
     "iopub.status.idle": "2024-07-06T10:27:54.097061Z",
     "shell.execute_reply": "2024-07-06T10:27:54.095894Z",
     "shell.execute_reply.started": "2024-07-06T10:27:54.091792Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T10:27:54.099982Z",
     "iopub.status.busy": "2024-07-06T10:27:54.099619Z",
     "iopub.status.idle": "2024-07-06T10:28:09.224841Z",
     "shell.execute_reply": "2024-07-06T10:28:09.223282Z",
     "shell.execute_reply.started": "2024-07-06T10:27:54.099951Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T10:28:09.227718Z",
     "iopub.status.busy": "2024-07-06T10:28:09.227280Z",
     "iopub.status.idle": "2024-07-06T10:28:29.136293Z",
     "shell.execute_reply": "2024-07-06T10:28:29.134578Z",
     "shell.execute_reply.started": "2024-07-06T10:28:09.227669Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install git+https://github.com/tensorflow/docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a GIF, you will need the `imageio` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T10:28:29.139131Z",
     "iopub.status.busy": "2024-07-06T10:28:29.138545Z",
     "iopub.status.idle": "2024-07-06T10:28:29.148094Z",
     "shell.execute_reply": "2024-07-06T10:28:29.146569Z",
     "shell.execute_reply.started": "2024-07-06T10:28:29.139075Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T10:28:29.150990Z",
     "iopub.status.busy": "2024-07-06T10:28:29.150378Z",
     "iopub.status.idle": "2024-07-06T10:28:29.736306Z",
     "shell.execute_reply": "2024-07-06T10:28:29.734972Z",
     "shell.execute_reply.started": "2024-07-06T10:28:29.150941Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "x=[]\n",
    "for img in df[\"image_path\"]:\n",
    "    img=cv2.imread(str(img)) #That read the image\n",
    "    img=cv2.resize(img,(28,28)) #That resize the image to 170x170\n",
    "    img=img/255.0 #That normalize the image-->Normalizing makes the rgb values between 0 and 1. That facilitates our computers to process\n",
    "    x.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T10:28:29.738423Z",
     "iopub.status.busy": "2024-07-06T10:28:29.738004Z",
     "iopub.status.idle": "2024-07-06T10:28:29.744579Z",
     "shell.execute_reply": "2024-07-06T10:28:29.742975Z",
     "shell.execute_reply.started": "2024-07-06T10:28:29.738391Z"
    }
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T10:28:29.746716Z",
     "iopub.status.busy": "2024-07-06T10:28:29.746357Z",
     "iopub.status.idle": "2024-07-06T10:28:31.359645Z",
     "shell.execute_reply": "2024-07-06T10:28:31.358291Z",
     "shell.execute_reply.started": "2024-07-06T10:28:29.746688Z"
    }
   },
   "outputs": [],
   "source": [
    "# Batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T10:28:31.364459Z",
     "iopub.status.busy": "2024-07-06T10:28:31.364049Z",
     "iopub.status.idle": "2024-07-06T10:28:31.379939Z",
     "shell.execute_reply": "2024-07-06T10:28:31.378521Z",
     "shell.execute_reply.started": "2024-07-06T10:28:31.364426Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    \n",
    "    model.add(layers.Input(shape=(100,)))\n",
    "    \n",
    "    \n",
    "    model.add(layers.Dense(7*7*256, use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256)  \n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 28, 28, 32)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(1, 1), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 3)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function, `make_generator_model()`, defines and returns a generator model using TensorFlow and Keras. The model starts with an input layer that takes a 100-dimensional vector, which is then transformed through a series of layers: a dense layer that reshapes the input into a 7x7x256 tensor, followed by several transposed convolutional layers (Conv2DTranspose) with batch normalization and LeakyReLU activation functions. These layers successively upsample the tensor to dimensions 14x14x64 and 28x28x32, ultimately generating a 28x28x3 image with a final transposed convolutional layer using a tanh activation function. This model is designed for generating images, typically used in Generative Adversarial Networks (GANs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T10:28:31.382386Z",
     "iopub.status.busy": "2024-07-06T10:28:31.381868Z",
     "iopub.status.idle": "2024-07-06T10:28:31.903593Z",
     "shell.execute_reply": "2024-07-06T10:28:31.902250Z",
     "shell.execute_reply.started": "2024-07-06T10:28:31.382342Z"
    }
   },
   "outputs": [],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0])\n",
    "#To test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T10:28:31.905897Z",
     "iopub.status.busy": "2024-07-06T10:28:31.905416Z",
     "iopub.status.idle": "2024-07-06T10:28:31.915657Z",
     "shell.execute_reply": "2024-07-06T10:28:31.914340Z",
     "shell.execute_reply.started": "2024-07-06T10:28:31.905853Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                            input_shape=[28, 28, 3]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function, `make_discriminator_model()`, defines and returns a discriminator model using TensorFlow and Keras. The model begins with a convolutional layer (Conv2D) with 64 filters, a 5x5 kernel size, and a stride of 2, applied to an input shape of 28x28x3. It is followed by a LeakyReLU activation function and a dropout layer with a 0.3 dropout rate. This pattern is repeated in a second convolutional layer with 128 filters. The output is then flattened into a single dimension and passed through a dense layer with a single neuron to produce the final output. This model is used to classify images as real or fake in a Generative Adversarial Network (GAN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T10:28:31.917906Z",
     "iopub.status.busy": "2024-07-06T10:28:31.917407Z",
     "iopub.status.idle": "2024-07-06T10:28:32.050744Z",
     "shell.execute_reply": "2024-07-06T10:28:32.049611Z",
     "shell.execute_reply.started": "2024-07-06T10:28:31.917861Z"
    }
   },
   "outputs": [],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print(decision)\n",
    "#To test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T10:28:32.052532Z",
     "iopub.status.busy": "2024-07-06T10:28:32.052183Z",
     "iopub.status.idle": "2024-07-06T10:28:32.058937Z",
     "shell.execute_reply": "2024-07-06T10:28:32.056969Z",
     "shell.execute_reply.started": "2024-07-06T10:28:32.052502Z"
    }
   },
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T10:28:32.060815Z",
     "iopub.status.busy": "2024-07-06T10:28:32.060354Z",
     "iopub.status.idle": "2024-07-06T10:28:32.070136Z",
     "shell.execute_reply": "2024-07-06T10:28:32.068720Z",
     "shell.execute_reply.started": "2024-07-06T10:28:32.060771Z"
    }
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T10:28:32.072545Z",
     "iopub.status.busy": "2024-07-06T10:28:32.072063Z",
     "iopub.status.idle": "2024-07-06T10:28:32.083365Z",
     "shell.execute_reply": "2024-07-06T10:28:32.082111Z",
     "shell.execute_reply.started": "2024-07-06T10:28:32.072500Z"
    }
   },
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T10:28:32.085795Z",
     "iopub.status.busy": "2024-07-06T10:28:32.085325Z",
     "iopub.status.idle": "2024-07-06T10:28:32.100512Z",
     "shell.execute_reply": "2024-07-06T10:28:32.099094Z",
     "shell.execute_reply.started": "2024-07-06T10:28:32.085753Z"
    }
   },
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T10:28:32.102973Z",
     "iopub.status.busy": "2024-07-06T10:28:32.102469Z",
     "iopub.status.idle": "2024-07-06T10:28:32.113182Z",
     "shell.execute_reply": "2024-07-06T10:28:32.111885Z",
     "shell.execute_reply.started": "2024-07-06T10:28:32.102929Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T10:28:32.115554Z",
     "iopub.status.busy": "2024-07-06T10:28:32.115145Z",
     "iopub.status.idle": "2024-07-06T10:28:32.127828Z",
     "shell.execute_reply": "2024-07-06T10:28:32.126437Z",
     "shell.execute_reply.started": "2024-07-06T10:28:32.115522Z"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 500\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 1\n",
    "\n",
    "# You will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T10:28:32.129997Z",
     "iopub.status.busy": "2024-07-06T10:28:32.129521Z",
     "iopub.status.idle": "2024-07-06T10:28:32.141342Z",
     "shell.execute_reply": "2024-07-06T10:28:32.139999Z",
     "shell.execute_reply.started": "2024-07-06T10:28:32.129943Z"
    }
   },
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training=True)\n",
    "\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T10:28:32.143451Z",
     "iopub.status.busy": "2024-07-06T10:28:32.142999Z",
     "iopub.status.idle": "2024-07-06T10:28:32.160789Z",
     "shell.execute_reply": "2024-07-06T10:28:32.159425Z",
     "shell.execute_reply.started": "2024-07-06T10:28:32.143417Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "    # Produce images for the GIF as you go\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  display.clear_output(wait=True)\n",
    "  generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T10:28:32.163132Z",
     "iopub.status.busy": "2024-07-06T10:28:32.162628Z",
     "iopub.status.idle": "2024-07-06T10:28:32.174646Z",
     "shell.execute_reply": "2024-07-06T10:28:32.173286Z",
     "shell.execute_reply.started": "2024-07-06T10:28:32.163089Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    # Notice `training` is set to False.\n",
    "    # This is so all layers run in inference mode (batchnorm).\n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        normalized_image = (predictions[i] + 1) / 2.0\n",
    "        plt.imshow(normalized_image)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T10:28:32.176942Z",
     "iopub.status.busy": "2024-07-06T10:28:32.176488Z",
     "iopub.status.idle": "2024-07-06T11:32:38.575465Z",
     "shell.execute_reply": "2024-07-06T11:32:38.573713Z",
     "shell.execute_reply.started": "2024-07-06T10:28:32.176902Z"
    }
   },
   "outputs": [],
   "source": [
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:32:38.578964Z",
     "iopub.status.busy": "2024-07-06T11:32:38.577996Z",
     "iopub.status.idle": "2024-07-06T11:32:38.585637Z",
     "shell.execute_reply": "2024-07-06T11:32:38.584204Z",
     "shell.execute_reply.started": "2024-07-06T11:32:38.578907Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display a single image using the epoch number\n",
    "def display_image(epoch_no):\n",
    "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:32:38.589089Z",
     "iopub.status.busy": "2024-07-06T11:32:38.588058Z",
     "iopub.status.idle": "2024-07-06T11:32:38.632681Z",
     "shell.execute_reply": "2024-07-06T11:32:38.631071Z",
     "shell.execute_reply.started": "2024-07-06T11:32:38.589029Z"
    }
   },
   "outputs": [],
   "source": [
    "display_image(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:32:38.636595Z",
     "iopub.status.busy": "2024-07-06T11:32:38.635338Z",
     "iopub.status.idle": "2024-07-06T11:32:45.369133Z",
     "shell.execute_reply": "2024-07-06T11:32:45.367524Z",
     "shell.execute_reply.started": "2024-07-06T11:32:38.636532Z"
    }
   },
   "outputs": [],
   "source": [
    "anim_file = 'dcgan.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "  filenames = glob.glob('image*.png')\n",
    "  filenames = sorted(filenames)\n",
    "  for filename in filenames:\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "  image = imageio.imread(filename)\n",
    "  writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:32:45.371471Z",
     "iopub.status.busy": "2024-07-06T11:32:45.371050Z",
     "iopub.status.idle": "2024-07-06T11:32:45.405199Z",
     "shell.execute_reply": "2024-07-06T11:32:45.403907Z",
     "shell.execute_reply.started": "2024-07-06T11:32:45.371436Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow_docs.vis.embed as embed\n",
    "embed.embed_file(anim_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:32:45.412558Z",
     "iopub.status.busy": "2024-07-06T11:32:45.412143Z",
     "iopub.status.idle": "2024-07-06T11:32:45.443396Z",
     "shell.execute_reply": "2024-07-06T11:32:45.442196Z",
     "shell.execute_reply.started": "2024-07-06T11:32:45.412526Z"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm image*.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:52:36.572979Z",
     "iopub.status.busy": "2024-07-06T11:52:36.572437Z",
     "iopub.status.idle": "2024-07-06T11:52:40.625126Z",
     "shell.execute_reply": "2024-07-06T11:52:40.623643Z",
     "shell.execute_reply.started": "2024-07-06T11:52:36.572939Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "def generate_and_save_images(model, num_images=1000, output_dir='generated_images'):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    paths = []\n",
    "    noise_dim = 100\n",
    "    random_noise = tf.random.normal([num_images, noise_dim])\n",
    "    predictions = model(random_noise, training=False)\n",
    "\n",
    "    for i in range(num_images):\n",
    "        file_path = os.path.join(output_dir, f'image_{i}.png')\n",
    "        normalized_image = (predictions[i] + 1) / 2.0\n",
    "        normalized_image = normalized_image.numpy()\n",
    "        plt.imsave(file_path, normalized_image)\n",
    "        paths.append(file_path)\n",
    "\n",
    "    return paths\n",
    "\n",
    "paths = generate_and_save_images(generator, num_images=1000)\n",
    "gen_df = pd.DataFrame(paths, columns=['image_path'])\n",
    "gen_df.to_csv('generated_image_paths.csv', index=False)\n",
    "\n",
    "print(gen_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function, `generate_and_save_images()`, generates and saves synthetic images using a trained generator model in TensorFlow. It starts by ensuring the existence of an output directory, then creates random noise to feed into the generator model, producing the desired number of images. Each generated image is normalized and saved as a PNG file in the specified directory, with their file paths recorded in a list. The paths are then compiled into a pandas DataFrame, which is saved as a CSV file for easy reference. Finally, the function prints the first few rows of the DataFrame to confirm the operation's success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:52:56.259444Z",
     "iopub.status.busy": "2024-07-06T11:52:56.258980Z",
     "iopub.status.idle": "2024-07-06T11:52:56.266184Z",
     "shell.execute_reply": "2024-07-06T11:52:56.265069Z",
     "shell.execute_reply.started": "2024-07-06T11:52:56.259411Z"
    }
   },
   "outputs": [],
   "source": [
    "#Fake images\n",
    "gen_df[\"target\"]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:52:56.910768Z",
     "iopub.status.busy": "2024-07-06T11:52:56.910310Z",
     "iopub.status.idle": "2024-07-06T11:52:56.922507Z",
     "shell.execute_reply": "2024-07-06T11:52:56.921195Z",
     "shell.execute_reply.started": "2024-07-06T11:52:56.910724Z"
    }
   },
   "outputs": [],
   "source": [
    "gen_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:52:57.717737Z",
     "iopub.status.busy": "2024-07-06T11:52:57.715086Z",
     "iopub.status.idle": "2024-07-06T11:52:57.733982Z",
     "shell.execute_reply": "2024-07-06T11:52:57.732599Z",
     "shell.execute_reply.started": "2024-07-06T11:52:57.717663Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(\"image_id\", axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:52:58.511814Z",
     "iopub.status.busy": "2024-07-06T11:52:58.510920Z",
     "iopub.status.idle": "2024-07-06T11:52:58.528753Z",
     "shell.execute_reply": "2024-07-06T11:52:58.527348Z",
     "shell.execute_reply.started": "2024-07-06T11:52:58.511734Z"
    }
   },
   "outputs": [],
   "source": [
    "#Real images\n",
    "df[\"target\"]=1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:52:59.346449Z",
     "iopub.status.busy": "2024-07-06T11:52:59.346037Z",
     "iopub.status.idle": "2024-07-06T11:52:59.364134Z",
     "shell.execute_reply": "2024-07-06T11:52:59.362856Z",
     "shell.execute_reply.started": "2024-07-06T11:52:59.346415Z"
    }
   },
   "outputs": [],
   "source": [
    "gen_df[\"image_path\"]=\"/kaggle/working/\"+gen_df[\"image_path\"]\n",
    "gen_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:53:00.230509Z",
     "iopub.status.busy": "2024-07-06T11:53:00.230082Z",
     "iopub.status.idle": "2024-07-06T11:53:00.245316Z",
     "shell.execute_reply": "2024-07-06T11:53:00.244038Z",
     "shell.execute_reply.started": "2024-07-06T11:53:00.230477Z"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.concat([df,gen_df])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:53:03.974651Z",
     "iopub.status.busy": "2024-07-06T11:53:03.974245Z",
     "iopub.status.idle": "2024-07-06T11:53:04.650203Z",
     "shell.execute_reply": "2024-07-06T11:53:04.648777Z",
     "shell.execute_reply.started": "2024-07-06T11:53:03.974621Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "train=[]\n",
    "for image in df[\"image_path\"]:\n",
    "    img=cv2.imread(image)\n",
    "    img=cv2.resize(img,(28,28))\n",
    "    img=img/255\n",
    "    train.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:53:04.653226Z",
     "iopub.status.busy": "2024-07-06T11:53:04.652655Z",
     "iopub.status.idle": "2024-07-06T11:53:04.672638Z",
     "shell.execute_reply": "2024-07-06T11:53:04.670999Z",
     "shell.execute_reply.started": "2024-07-06T11:53:04.653180Z"
    }
   },
   "outputs": [],
   "source": [
    "train=np.array(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:53:04.996700Z",
     "iopub.status.busy": "2024-07-06T11:53:04.995769Z",
     "iopub.status.idle": "2024-07-06T11:53:05.007106Z",
     "shell.execute_reply": "2024-07-06T11:53:05.005349Z",
     "shell.execute_reply.started": "2024-07-06T11:53:04.996661Z"
    }
   },
   "outputs": [],
   "source": [
    "y=df[\"target\"]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:53:08.430851Z",
     "iopub.status.busy": "2024-07-06T11:53:08.430412Z",
     "iopub.status.idle": "2024-07-06T11:53:09.299940Z",
     "shell.execute_reply": "2024-07-06T11:53:09.298617Z",
     "shell.execute_reply.started": "2024-07-06T11:53:08.430815Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:53:10.727824Z",
     "iopub.status.busy": "2024-07-06T11:53:10.727402Z",
     "iopub.status.idle": "2024-07-06T11:53:10.736497Z",
     "shell.execute_reply": "2024-07-06T11:53:10.734953Z",
     "shell.execute_reply.started": "2024-07-06T11:53:10.727790Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Flatten, Input, MaxPooling2D, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:54:52.643326Z",
     "iopub.status.busy": "2024-07-06T11:54:52.642824Z",
     "iopub.status.idle": "2024-07-06T11:54:52.829285Z",
     "shell.execute_reply": "2024-07-06T11:54:52.827862Z",
     "shell.execute_reply.started": "2024-07-06T11:54:52.643288Z"
    }
   },
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Input(shape=(28, 28, 3)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))  \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(80, kernel_size=(3, 3), activation='relu', padding='same'))  \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(100, kernel_size=(3, 3), activation='relu', padding='same'))  \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))  \n",
    "model.add(Dense(1, activation='sigmoid'))  \n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines and compiles a Convolutional Neural Network (CNN) model using TensorFlow and Keras. The model starts with an input layer for images of shape 28x28x3, followed by four convolutional layers with ReLU activation and 'same' padding, each accompanied by a max-pooling layer to reduce spatial dimensions. After the convolutional layers, the model flattens the output and passes it through a dense layer with 128 neurons and ReLU activation. Finally, it has an output dense layer with a single neuron and sigmoid activation for binary classification. The model is compiled with the Adam optimizer, binary cross-entropy loss, and accuracy as a performance metric. The `model.summary()` function is called to display the model's architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:54:56.347047Z",
     "iopub.status.busy": "2024-07-06T11:54:56.346577Z",
     "iopub.status.idle": "2024-07-06T11:55:32.221959Z",
     "shell.execute_reply": "2024-07-06T11:55:32.220835Z",
     "shell.execute_reply.started": "2024-07-06T11:54:56.347002Z"
    }
   },
   "outputs": [],
   "source": [
    "history=model.fit(X_train,y_train,epochs=20,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T11:55:38.347915Z",
     "iopub.status.busy": "2024-07-06T11:55:38.347469Z",
     "iopub.status.idle": "2024-07-06T11:55:38.408647Z",
     "shell.execute_reply": "2024-07-06T11:55:38.407631Z",
     "shell.execute_reply.started": "2024-07-06T11:55:38.347877Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 17px\">This project combines the strengths of DCGAN and CNN to create a powerful tool for image classification. Through the integration of advanced machine learning algorithms and meticulous data preparation, we aim to achieve high accuracy in distinguishing between real and synthetic retina images.</p>"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5343465,
     "sourceId": 8877349,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
